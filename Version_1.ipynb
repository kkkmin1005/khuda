{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORmjcHlT-Qgm"
      },
      "source": [
        "# **Import Library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReeHrtxm-LYC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "import time\n",
        "import random\n",
        "import copy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajdGNW55-WUN"
      },
      "source": [
        "# **Define Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnrVUVGl-ZGr"
      },
      "outputs": [],
      "source": [
        "\"\"\"# **1) Model define**\n",
        "### trans_VGG에서 사용할 함수인 conv_2 define\n",
        "\"\"\"\n",
        "\n",
        "def conv_2(in_dim, out_dim):\n",
        "    model = nn.Sequential(\n",
        "        nn.Conv2d(in_dim, out_dim, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(),# Model define\n",
        "        nn.Conv2d(out_dim, out_dim, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2,2)\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def conv_3(in_dim, out_dim):\n",
        "    model = nn.Sequential(\n",
        "        nn.Conv2d(in_dim, out_dim, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(),# Model define\n",
        "        nn.Conv2d(out_dim, out_dim, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(out_dim, out_dim, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(out_dim, out_dim, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2,2)\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "conv_2 함수는 합성곱 레이어로 3개의 레이어를 가진다. \n",
        "1. 크기가 3인 convolution filter\n",
        "2. 크기가 3인 convolution filter\n",
        "3. 크기가 2인 max pooling filter\n",
        "\n",
        "conv_3 함수는 합성곱 레이어로 5개의 레이어를 가진다.\n",
        "1. 크기가 3인 convolution filter\n",
        "2. 크기가 3인 convolution filter\n",
        "3. 크기가 3인 convolution filter\n",
        "4. 크기가 3인 convolution filter\n",
        "5. 크기가 2인 max pooling filter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtjKQ3Ss-eOM"
      },
      "source": [
        "# **Define trans_VGG class**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ty-Lx7--jv0"
      },
      "outputs": [],
      "source": [
        "class trans_VGG(nn.Module):\n",
        "    def __init__(self, base_dim):\n",
        "        super(trans_VGG, self).__init__()\n",
        "        self.feature = nn.Sequential(\n",
        "            conv_2(3, base_dim),\n",
        "            conv_2(base_dim, base_dim*2),\n",
        "            conv_2(base_dim*2, base_dim*4),\n",
        "            conv_3(base_dim*4, base_dim*8),\n",
        "            conv_3(base_dim*8, base_dim*8)\n",
        "        )\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Linear(base_dim*8*7*7, base_dim*4*7*7),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(base_dim*4*7*7, base_dim*2*7*7),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(base_dim*2*7*7, base_dim*7*7)\n",
        "        )\n",
        "        for param in self.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc_layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "해당 코드는 vgg 모델의 클래스를 정의 하는 과정이다.\n",
        "\n",
        "생성자 부분\n",
        "기본 차원을 입력받고 총 5개의 레이어를 거치며 채널수를 두배씩 늘린다.\n",
        "또한 마지막 부분에서 conv_3를 두번 적용하여 깊은 층에서 깊이있는 특징을 추출하게 된다.\n",
        "\n",
        "fully connected 레이어 부분\n",
        "생성자에서 나온 특성을 1차원 벡터로 변환후 ReLU 활성화 함수를 거친다.\n",
        "이후 과적합을 방지하기 위해 드롭아웃을 사용한다.\n",
        "\n",
        "순전파 부분\n",
        "합성곱 레이어를 통해 데이터를 처리하고 fc부분을 통해 처리되어 최종적으로 모델이 예측한 값을 반환한다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JlwvIx9-oB3"
      },
      "source": [
        "- Hyper_paremeter : Learning rate, momentum, weight decay 등은 논문의 Hyper peremeter value로 초기화\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_79OsMOG-olp"
      },
      "outputs": [],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "seed = time.time()\n",
        "\n",
        "def custom_init_weights(m):\n",
        "  if seed is not None:\n",
        "    torch.manual_seed(seed)\n",
        "  if isinstance(m, torch.nn.Linear) and m.weight is not None:\n",
        "    init.normal_(m.weight, mean=1, std=0.01)\n",
        "    if m.bias is not None:\n",
        "      init.constant_(m.bias, 0)\n",
        "\n",
        "model = trans_VGG(base_dim=64)\n",
        "\n",
        "loss = nn.BCELoss()\n",
        "optimizer =torch.optim.SGD(model.parameters(), lr = 0.01,momentum = 0.9, weight_decay = 0.0005)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='max', patience=10, factor=0.1, verbose=True)\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.RandomCrop(224)])\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "랜덤 시드를 발급하고 레이어에 대한 가중치를 초기화 한다.\n",
        "레이어의 가중치는 평균 = 1, 표준편차 = 0.01이며 bias와 constant는 0으로 초기화 한다.\n",
        "\n",
        "이후 BCE 손실함수를 불러온다.\n",
        "\n",
        "학습 스케쥴러를 성정하여 학습이 정체될 때 학습률을 동적으로 조정한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDUjpjGy-wJn"
      },
      "source": [
        "# **Import Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7NWSJZD-yoP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Project 3 폴더 경로\n",
        "project_folder = '/content/drive/MyDrive/Project3'\n",
        "\n",
        "image = []\n",
        "label = []\n",
        "\n",
        "# Project 3 폴더 내부의 세부 폴더를 확인하고 이미지와 라벨 데이터 생성\n",
        "for subdir, _, files in os.walk(project_folder):\n",
        "    for file in files:\n",
        "        # 이미지 파일인지 확인\n",
        "        if file.endswith(('png', 'jpg', 'jpeg')):\n",
        "            image_path = os.path.join(subdir, file)\n",
        "            image.append(image_path)\n",
        "\n",
        "            # 이미지가 속한 세부 폴더의 이름을 라벨로 사용\n",
        "            label_name = os.path.basename(subdir)\n",
        "            label.append(label_name)\n",
        "\n",
        "indices = np.random.permutation(len(image))\n",
        "IMAGE = [image[i] for i in indices]\n",
        "LABEL = [label[i] for i in indices]\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        image = transforms.RandomCrop(224)(image)\n",
        "        image = transforms.ToTensor()(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "TRAINING_image = []\n",
        "TRAINING_label = []\n",
        "TEST_image = []\n",
        "TEST_label = []\n",
        "\n",
        "for i in range(0,80):\n",
        "  for j in range(0,20):\n",
        "    for k in range(0,2):\n",
        "      TRAINING_image.append(image[200*j+i+k])\n",
        "      TRAINING_label.append(label[200*j+i+k])\n",
        "\n",
        "for i in range(80,100):\n",
        "  for j in range(0,20):\n",
        "    for k in range(0,2):\n",
        "      TEST_image.append(image[200*j+i+k])\n",
        "      TEST_label.append(label[200*j+i+k])\n",
        "\n",
        "train_dataset = CustomDataset(TRAINING_image, TRAINING_label, transform = transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE,num_workers=2)\n",
        "test_dataset = CustomDataset(TEST_image, TEST_label, transform = transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE,num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61PMWGKo-2dQ"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBiV7BHk-4MH"
      },
      "outputs": [],
      "source": [
        "\"\"\"# **3) TRAINING**\"\"\"\n",
        "\n",
        "EPOCH = 80\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "start_time = time.time()\n",
        "train_acc_lst, test_acc_lst = [],[]\n",
        "\n",
        "for epoch in range(EPOCH):\n",
        "  model.train()\n",
        "  correct_pred, num_examples = 0, 3200\n",
        "  for i, (_image1, _label1) in enumerate(train_loader):\n",
        "    image1 = _image1.to(DEVICE)\n",
        "    label1 = _label1[0]\n",
        "    vector1_tensor = model(image1)\n",
        "\n",
        "    if (i == 0): #Exception Case\n",
        "      image2 = image1\n",
        "      label2 = label1\n",
        "      vector2_tensor = vector1_tensor\n",
        "\n",
        "    similarity =  F.cosine_similarity(vector1_tensor, vector2_tensor, dim= -1)\n",
        "    scaled_similarity = torch.sigmoid(similarity)\n",
        "\n",
        "    if label1 == label2 and scaled_similarity.item() > 0.5:\n",
        "        correct_pred += 1\n",
        "    elif label1 != label2 and scaled_similarity.item() < 0.5:\n",
        "        correct_pred += 1\n",
        "\n",
        "    if label1 == label2:\n",
        "      target_vector = [1]\n",
        "    else :\n",
        "      target_vector = [0]\n",
        "\n",
        "    target_tensor = torch.tensor(target_vector).float()\n",
        "    target_tensor = target_tensor.to(DEVICE)\n",
        "    optimizer.zero_grad()\n",
        "    cost = loss(scaled_similarity, target_tensor)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if not i % 40:\n",
        "      print (f'Epoch: {epoch:03d}/{EPOCH:03d} | '\n",
        "            f'Batch {i:03d}/{len(train_loader):03d} |'\n",
        "             f' Cost: {cost:.4f}')\n",
        "\n",
        "    #연산량 감소를 위한 텐서 재활용\n",
        "    image2 = image1.clone()\n",
        "    label2 = label1\n",
        "    vector2_tensor = vector1_tensor.detach().clone()\n",
        "\n",
        "elapsed = (time.time() - start_time)/60\n",
        "print(f'Total Training Time: {elapsed:.2f} min')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. 훈련 설정\n",
        "에포크를 80으로 설정\n",
        "2. 학습\n",
        "이미지 데이터를 배치 단위로 가져와 gpu 또는 cpu에 맞게 학습을 진행한다.\n",
        "이후 모델에서 나온 특성들을 벡터로 저장해준다.\n",
        "3. 유사도 측정\n",
        "결과 벡터들을 활용해 코사인 유사도를 구하고 유사도를 0.5를 기준으로 0,1로 나눈다.\n",
        "4. 손실 계산\n",
        "계산된 유사도와 실제 값과 손실을 구하고 손실함수에 그래디언트 역전파를 사용하여 가중치를 업데이트 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 성능 향상 제안\n",
        "\n",
        "SE block 활용\n",
        "- Spatial Squeeze and Channel Excitation\n",
        "\n",
        "해당 알고리즘은 spatial squeeze 부분과 channel excitation 부분으로 나뉘는데\n",
        "첫번째 부분은 각 채널을 대표하는 정보를 추출하고\n",
        "두번째 부분은 대표값을 이용해 채널들간의 비선형 특징을 파악한다.\n",
        "이후 채널별 중요도 값을 기존의 이미지 행렬에 곱한다.\n",
        "\n",
        "결과적으로 전체적인 맥락을 고려해서 상황에 맞는 채널을 강조할 수 있어 정확도를 향상 시킬수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class trans_VGG_with_SE(nn.Module):\n",
        "    def __init__(self, base_dim):\n",
        "        super(trans_VGG_with_SE, self).__init__()\n",
        "        self.feature = nn.Sequential(\n",
        "            conv_2(3, base_dim),\n",
        "            SEBlock(base_dim),  # SE Block 추가\n",
        "            conv_2(base_dim, base_dim*2),\n",
        "            SEBlock(base_dim*2),  # SE Block 추가\n",
        "            conv_2(base_dim*2, base_dim*4),\n",
        "            SEBlock(base_dim*4),  # SE Block 추가\n",
        "            conv_3(base_dim*4, base_dim*8),\n",
        "            SEBlock(base_dim*8),  # SE Block 추가\n",
        "            conv_3(base_dim*8, base_dim*8),\n",
        "            SEBlock(base_dim*8)  # SE Block 추가\n",
        "        )\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Linear(base_dim*8*7*7, base_dim*4*7*7),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(base_dim*4*7*7, base_dim*2*7*7),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(base_dim*2*7*7, base_dim*7*7)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc_layer(x)\n",
        "        return x\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
